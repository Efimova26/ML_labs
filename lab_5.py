# -*- coding: utf-8 -*-
"""Labwork_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vvzJVsJjNPA0s9PmwCQofHd71QpgLIXZ

**Лабораторная работа: Прогнозирование временных рядов занятости в индустрии гостеприимства Калифорнии**

**Цели работы**

- Изучить и визуализировать временной ряд месячной занятости сотрудников индустрии гостеприимства в Калифорнии.

- Выявить трендовые, сезонные и случайные компоненты ряда.

- Проверить стационарность ряда и при необходимости выполнить преобразования.

- Построить модель прогнозирования временного ряда и оценить её точность.

- Проанализировать влияние сезонности и тренда на прогноз.

**Задачи**

1. Загрузить и предобработать данные, проверить наличие пропусков.

2. Построить график временного ряда и провести визуальный анализ.

3. Выполнить декомпозицию ряда на тренд, сезонность и остатки (аддитивная и мультипликативная модели).

4. Проверить стационарность с помощью ADF и KPSS тестов.

5. При необходимости выполнить логарифмирование и разности для достижения стационарности.

6. Разделить ряд на обучающую и тестовую выборки.

7. Построить модель прогнозирования (Holt–Winters) с учетом тренда и сезонности.

8. Сделать прогноз на несколько периодов и оценить точность с помощью MAE, RMSE, MAPE и R².

9. Визуализировать прогноз вместе с исходным рядом и проанализировать результаты.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 1. Загрузка данных
path = "/content/drive/MyDrive/Лабораторные работы /Лабораторная 5/lab5.csv"
df = pd.read_csv(path)

# Автоматическое определение столбцов даты и значения
date_col = None
value_col = None
for c in df.columns:
    low = c.lower()
    if any(x in low for x in ["date", "month", "period", "time"]):
        date_col = c
    if any(x in low for x in ["employee", "emp", "count", "value", "workers", "number"]):
        value_col = c
if date_col is None:
    date_col = df.columns[0]
if value_col is None:
    value_col = df.columns[1] if len(df.columns) > 1 else df.columns[0]

# Преобразование даты и установка индекса
df[date_col] = pd.to_datetime(df[date_col])
df = df.sort_values(date_col).set_index(date_col)
ts = df[value_col].astype(float)
ts = ts.asfreq('MS')  # ежемесячная частота

# --- Обработка пропусков ---
before = len(ts)
ts = ts.dropna()
after = len(ts)
if before != after:
    print(f"Обнаружены пропуски: удалено {before - after} наблюдений методом dropna().")
else:
    print("Пропусков не обнаружено. Данные полные.")

print(f"Используется: дата = '{date_col}', значение = '{value_col}'")
print(f"Диапазон данных: {ts.index.min().date()} — {ts.index.max().date()} ({len(ts)} наблюдений)")

# 2. Визуализация исходного ряда
plt.figure(figsize=(12,4))
plt.plot(ts, label="Исходный ряд")
plt.title("Месячная занятость в индустрии гостеприимства Калифорнии")
plt.xlabel("Дата")
plt.ylabel(f"{value_col} (тыс. чел.)")
plt.grid(True)
plt.legend()
plt.show()

# 3. ACF и PACF

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

fig, ax = plt.subplots(2, 1, figsize=(12,6))
plot_acf(ts, ax=ax[0], lags=36)
plot_pacf(ts, ax=ax[1], lags=36, method='ywm')
ax[0].set_title("ACF (автокорреляция)")
ax[1].set_title("PACF (частная автокорреляция)")
plt.tight_layout()
plt.show()

# 4. Декомпозиция ряда

from statsmodels.tsa.seasonal import seasonal_decompose

period = 12  # сезонность (12 месяцев)

# Additive
decomp_add = seasonal_decompose(ts, model='additive', period=period, extrapolate_trend='freq')
fig = decomp_add.plot()
fig.set_size_inches(12, 9)
fig.suptitle("Additive decomposition (аддитивная модель)", fontsize=14, y=1.02)
for ax in fig.axes:
    ax.grid(True)
    ax.set_xlabel("Дата")
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Multiplicative
decomp_mul = seasonal_decompose(ts, model='multiplicative', period=period, extrapolate_trend='freq')
fig = decomp_mul.plot()
fig.set_size_inches(12, 9)
fig.suptitle("Multiplicative decomposition (мультипликативная модель)", fontsize=14, y=1.02)
for ax in fig.axes:
    ax.grid(True)
    ax.set_xlabel("Дата")
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# 5. Проверка стационарности

from statsmodels.tsa.stattools import adfuller, kpss
from tabulate import tabulate

def adf_test(series):
    result = adfuller(series.dropna(), autolag='AIC')
    return {
        "Тест": "ADF",
        "Статистика": round(result[0], 4),
        "p-value": round(result[1], 4),
        "Крит. значение (1%)": round(result[4]['1%'], 4),
        "Крит. значение (5%)": round(result[4]['5%'], 4),
        "Крит. значение (10%)": round(result[4]['10%'], 4)
    }

def kpss_test(series):
    result = kpss(series.dropna(), regression='c', nlags="auto")
    return {
        "Тест": "KPSS",
        "Статистика": round(result[0], 4),
        "p-value": round(result[1], 4),
        "Крит. значение (1%)": round(result[3]['1%'], 4),
        "Крит. значение (5%)": round(result[3]['5%'], 4),
        "Крит. значение (10%)": round(result[3]['10%'], 4)
    }

adf_res = adf_test(ts)
kpss_res = kpss_test(ts)

# Форматированный вывод
print("\nПроверка стационарности ряда:")
print(tabulate(
    [adf_res.values(), kpss_res.values()],
    headers=adf_res.keys(),
    tablefmt="fancy_grid",
    numalign="center",
    stralign="center"
))

# Интерпретация
print("\nИнтерпретация:")
if adf_res["p-value"] > 0.05 and kpss_res["p-value"] < 0.05:
    print("Ряд нестационарен (оба теста указывают на наличие тренда/сезонности).")
elif adf_res["p-value"] < 0.05 and kpss_res["p-value"] > 0.05:
    print("Ряд стационарен.")
else:
    print("Результаты тестов противоречивы, требуется дополнительный анализ.")

from google.colab import drive
drive.mount('/content/drive')

# 6. Преобразования (лог, разности)
use_log = (ts > 0).all()
if use_log:
    ts_log = np.log(ts)
else:
    ts_log = ts.copy()

ts_diff1 = ts_log.diff().dropna()
ts_diff12 = ts_log.diff(12).dropna()
ts_diff1_12 = ts_log.diff().diff(12).dropna()

# Проверка стационарности на разных преобразованиях
p_raw = adfuller(ts.dropna())[1]
p_diff1 = adfuller(ts_diff1)[1]
p_diff12 = adfuller(ts_diff12)[1]
p_diff1_12 = adfuller(ts_diff1_12)[1]

from tabulate import tabulate

data = [
    ["Исходный ряд", round(p_raw, 6), "Не стационарен" if p_raw > 0.05 else "Стационарен"],
    ["1-я разность", round(p_diff1, 6), "Стационарен" if p_diff1 < 0.05 else "Не стационарен"],
    ["Сезонная разность (12)", round(p_diff12, 6), "Стационарен" if p_diff12 < 0.05 else "Не стационарен"],
    ["1-я + сезонная разность", round(p_diff1_12, 6), "Стационарен" if p_diff1_12 < 0.05 else "Не стационарен"]
]

print("\nПроверка стационарности после преобразований (ADF p-values):")
print(tabulate(data, headers=["Преобразование", "p-value", "Вывод"], tablefmt="fancy_grid", stralign="center"))

# 7. Разделение на train/test
h = 24 if len(ts) >= 48 else 12  # 2 года теста
train = ts[:-h]
test = ts[-h:]
print(f"\nTrain: {train.index.min().date()} — {train.index.max().date()} ({len(train)})")
print(f"Test:  {test.index.min().date()} — {test.index.max().date()} ({len(test)})")

# 8. Модель Holt–Winters

from statsmodels.tsa.holtwinters import ExponentialSmoothing

hw_model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=period)
hw_fit = hw_model.fit(optimized=True)
fcast_hw = hw_fit.forecast(h)
fcast_hw = pd.Series(fcast_hw, index=test.index)

# 9. Оценка точности прогноза

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# MAE
mae_hw = mean_absolute_error(test, fcast_hw)

# RMSE
rmse_hw = np.sqrt(mean_squared_error(test, fcast_hw))

# MAPE
mape_hw = np.mean(np.abs((test - fcast_hw) / test)) * 100

# R²
r2_hw = r2_score(test, fcast_hw)

# Вывод результатов
print("Оценка точности модели Holt–Winters:")
print(f"MAE  : {mae_hw:.3f} тыс. чел.")
print(f"RMSE : {rmse_hw:.3f} тыс. чел.")
print(f"MAPE : {mape_hw:.2f} %")
print(f"R²   : {r2_hw:.3f}")

# 10. График прогноза Holt–Winters
plt.figure(figsize=(12,5))
plt.plot(train.index, train, label='Train')
plt.plot(test.index, test, label='Test (факт)')
plt.plot(fcast_hw.index, fcast_hw, label='Holt–Winters прогноз')
plt.title("Holt–Winters прогноз vs фактические данные")
plt.xlabel("Дата")
plt.ylabel(f"{value_col} (тыс. чел.)")
plt.legend()
plt.grid(True)
plt.show()

# ================================================
# ДОПОЛНИТЕЛЬНЫЙ БЛОК: СОХРАНЕНИЕ ВСЕХ ДАННЫХ ДЛЯ НОВОЙ ЛАБЫ С НЕЙРОСЕТЬЮ
# ================================================
import os
import zipfile

save_dir = "lab5_export"
os.makedirs(save_dir, exist_ok=True)

print("\n=== СОХРАНЕНИЕ ДАННЫХ ДЛЯ НЕЙРОСЕТИ ===")

# ---------- 1. Сохраняем исходный временной ряд ts ----------
ts.to_csv(f"{save_dir}/ts.csv")
print("✔ ts.csv сохранён")

# ---------- 2. Сохраняем train и test ----------
train.to_csv(f"{save_dir}/train.csv")
test.to_csv(f"{save_dir}/test.csv")
print("✔ train.csv и test.csv сохранены")

# ---------- 3. Функция для преобразования ряда в supervised ----------
def series_to_supervised(series, lag):
    X, y = [], []
    values = series.values
    for i in range(len(values) - lag):
        X.append(values[i:i+lag])
        y.append(values[i+lag])
    return np.array(X), np.array(y).reshape(-1, 1)

lag = 12  # для месячных данных логичное окно

# ---------- 4. Формируем X_train, y_train ----------
X_train, y_train = series_to_supervised(train, lag)

# ---------- 5. Формируем X_test, y_test ----------
combined = pd.concat([train[-lag:], test])
X_test_full, y_test_full = series_to_supervised(combined, lag)
X_test = X_test_full[-len(test):]
y_test = y_test_full[-len(test):]

# Сохраняем как CSV
np.savetxt(f"{save_dir}/X_train.csv", X_train, delimiter=",")
np.savetxt(f"{save_dir}/y_train.csv", y_train, delimiter=",")
np.savetxt(f"{save_dir}/X_test.csv", X_test, delimiter=",")
np.savetxt(f"{save_dir}/y_test.csv", y_test, delimiter=",")

# И как NPY
np.save(f"{save_dir}/X_train.npy", X_train)
np.save(f"{save_dir}/y_train.npy", y_train)
np.save(f"{save_dir}/X_test.npy", X_test)
np.save(f"{save_dir}/y_test.npy", y_test)

print("✔ Датасеты для нейросети сохранены (CSV и NPY)")

# ---------- 6. Архивируем всё в ZIP ----------
zip_path = "lab5_data_export.zip"
with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
    for fname in os.listdir(save_dir):
        zipf.write(os.path.join(save_dir, fname), arcname=fname)

print(f"✔ Архив сформирован: {zip_path}")
print("Теперь файл можно скачать!")

"""**Ход работы**

1. Предварительная обработка данных

- Данные загружены и преобразованы в формат временного ряда с ежемесячной частотой.

- Пропусков в данных не обнаружено.

2. Визуализация и анализ временного ряда

- Построен график временного ряда.

- Выявлены тренд (постепенный рост занятости) и сезонность (пики летом и в праздники).

3. Декомпозиция ряда

- Использованы аддитивная и мультипликативная модели.

- Сезонные компоненты показали регулярные колебания по годам, тренд — стабильный рост.

4. Проверка стационарности

- Исходный ряд нестационарен (ADF p-value = 0.993, KPSS p-value = 0.01).

- После логарифмирования и применения 1-й и сезонной разностей ряд стал стационарным.

5. Разделение на train/test

- Обучающая выборка: 1990–2016 (324 наблюдения).

- Тестовая выборка: 2017–2018 (24 наблюдения).

6. Построение модели прогнозирования

- Построена аддитивная модель Holt–Winters с учётом сезонности (12 месяцев) и тренда.

- Сформирован прогноз на 24 месяца.

7. Оценка точности прогноза

- MAE = 18.32 тыс. чел.

- RMSE = 22.63 тыс. чел.

- MAPE = 4.12 %

- R² = 0.92

8. Визуализация прогноза

- Прогноз повторяет сезонные колебания и общий тренд ряда.

- Небольшие расхождения наблюдаются в периоды пиков.

**Выводы**

1. Временной ряд занятости в индустрии гостеприимства Калифорнии обладает выраженной сезонностью и трендом.

2. Исходный ряд нестационарен, но после логарифмирования и применения разностей ряд становится стационарным.

3. Модель Holt–Winters с аддитивным трендом и сезонностью адекватно описывает ряд и прогнозирует занятость на следующие периоды с высокой точностью (R² = 0.92).

4. Сезонность сильно влияет на прогноз, особенно в летние и праздничные месяцы.

5. Для более долгосрочных прогнозов или учёта внешних факторов можно использовать SARIMA или Prophet.
"""