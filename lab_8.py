# -*- coding: utf-8 -*-
"""Copy of lab_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mcostnevYAXyWkkawuYQ6CIlezpMTanp

Тема: Трансферное обучение предобученной нейронной сети на датасете EuroSAT

Цель: Классификация спутниковых снимков Sentinel-2 по 10 классам.

EuroSAT — это открытый набор данных спутниковых снимков Sentinel-2, содержащий 27 000 изображений размером 64×64 пикселей в 10 классах:

- AnnualCrop

- Forest

- HerbaceousVegetation

- Residential

- Industrial

- PermanentCrop

- SeaLake

- Highway

- River

- Pasture

Задача: обучить классификатор, используя предобученную сверточную архитектуру, не обученную на EuroSAT ранее.

В этой работе применяется ResNet-50, предобученная на ImageNet. Оригинальный классификатор удаляется, веса сверточной части замораживаются, а новый классификатор обучается на EuroSAT.
"""

!pip install torch torchvision matplotlib seaborn tqdm --quiet

import os
import random
import torch

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", DEVICE)

"""Датасет скачивается из Zenodo, автоматически ищется папка с классами."""

# Скачивание и распаковка EuroSAT

!wget https://zenodo.org/record/7711810/files/EuroSAT_RGB.zip?download=1 -O /content/EuroSAT_RGB.zip
!unzip -q /content/EuroSAT_RGB.zip -d /content/EuroSAT_RGB

# Автоматический поиск папки с классами

def find_dataset_folder(root, min_classes=2):

    for dirpath, dirnames, filenames in os.walk(root):
        if len(dirnames) >= min_classes:

            has_files = all(len(os.listdir(os.path.join(dirpath, d))) > 0 for d in dirnames)
            if has_files:
                return dirpath
    return None

DATA_DIR = find_dataset_folder("/content/EuroSAT_RGB", min_classes=2)

if DATA_DIR is None:
    raise RuntimeError("Не удалось найти")
else:
    print("Найдена папка с классами:", DATA_DIR)
    print("Классы:", os.listdir(DATA_DIR))

from torchvision import transforms

"""Используются простые аугментации:

- Resize до 224×224 (под ResNet-50)

- RandomHorizontalFlip

- RandomRotation(15°)

- Normalize по статистике ImageNet
"""

# Аугментации и трансформации

IMG_SIZE = 224
train_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])
val_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

from torchvision import datasets
from torch.utils.data import random_split

"""Датасет разбивается на:

- 80% — обучение

- 20% — валидация
"""

# Dataset и split

full_dataset = datasets.ImageFolder(DATA_DIR)
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size],
                                          generator=torch.Generator().manual_seed(42))
train_dataset.dataset.transform = train_tf
val_dataset.dataset.transform = val_tf

class_names = full_dataset.classes
num_classes = len(class_names)
print(f"Number of classes: {num_classes}")

from torch.utils.data import DataLoader

# DataLoader

BATCH_SIZE = 64
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

import torch.nn as nn
from torchvision import models

"""Архитектура модели

Используется:

ResNet-50 (ImageNet)

↓ (заморожены все сверточные слои)

Полносвязный слой: 2048 → 10 классов

Замораживание основной части снижает переобучение и ускоряет обучение.
"""

# Загрузка предобученной ResNet-50

model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)
for param in model.parameters():
    param.requires_grad = False

# Новый классификатор
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, num_classes)
model.to(DEVICE)

from tqdm import tqdm
import torch.optim as optim

"""Используемые параметры:

- Оптимизатор: Adam, lr = 1e-3

- Критерий: CrossEntropyLoss

- Эпох: 10

- Батч: 64
"""

# Обучение

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)
EPOCHS = 10

train_losses, val_losses = [], []
train_accs, val_accs = [], []

for epoch in range(EPOCHS):
    # --- Training ---
    model.train()
    train_loss = 0
    correct = 0
    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} (train)"):
        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * imgs.size(0)
        correct += (outputs.argmax(1) == labels).sum().item()
    train_loss /= len(train_dataset)
    train_acc = correct / len(train_dataset)

    # --- Validation ---
    model.eval()
    val_loss = 0
    correct = 0
    with torch.no_grad():
        for imgs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{EPOCHS} (val)"):
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * imgs.size(0)
            correct += (outputs.argmax(1) == labels).sum().item()
    val_loss /= len(val_dataset)
    val_acc = correct / len(val_dataset)

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_acc)
    val_accs.append(val_acc)

    print(f"\nEpoch {epoch+1}/{EPOCHS} — Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f}")

"""Динамика обучения по эпохам:
| Эпоха | Train Accuracy | Val Accuracy |
| ----- | -------------- | ------------ |
| 1     | 0.903          | 0.918        |
| 2     | 0.923          | 0.925        |
| 3     | 0.933          | 0.932        |
| 4     | 0.939          | 0.933        |
| 5     | 0.946          | 0.936        |
| 6     | 0.950          | 0.939        |
| 7     | 0.951          | 0.943        |
| 8     | 0.954          | 0.940        |
| 9     | 0.956          | 0.942        |
| 10    | 0.959          | 0.941        |

"""

import matplotlib.pyplot as plt

"""Графики обучения

Loss:

Обучение проходит стабильно:

- Train Loss и Val Loss снижаются равномерно.

- Разрыв между ними минимальный, что говорит об отсутствии переобучения.

- На последних эпохах Val Loss выходит на плато — нормальное поведение модели на насыщении.

Accuracy:

Модель демонстрирует уверенный рост точности:

- Train Accuracy достигает примерно 95.9%,

- Val Accuracy — около 94.1%.

Небольшой разрыв между train и val говорит о хорошем качестве обобщения.
"""

# Графики Loss & Accuracy

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(train_losses,label='Train Loss')
plt.plot(val_losses,label='Val Loss')
plt.legend(); plt.title('Loss')

plt.subplot(1,2,2)
plt.plot(train_accs,label='Train Acc')
plt.plot(val_accs,label='Val Acc')
plt.legend(); plt.title('Accuracy')
plt.show()

from sklearn.metrics import confusion_matrix
import numpy as np

import seaborn as sns

"""Матрица ошибок

Сильные стороны модели

Наиболее уверенно классифицируются классы:

- SeaLake

- Forest

- Residential

- PermanentCrop

У них минимальное количество ошибок, часто единичные.

Наиболее сложные пары классов

Ошибки сконцентрированы в похожих по текстуре категориях:

- Highway ↔ Industrial

- Highway ↔ River

- River ↔ HerbaceousVegetation

- Pasture ↔ AnnualCrop

Эти классы действительно имеют схожие визуальные признаки на спутниковых снимках: цветовые пятна, прямые линии и участки земли.
"""

# Confusion Matrix

model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for imgs, labels in val_loader:
        outputs = model(imgs.to(DEVICE))
        all_preds.extend(outputs.argmax(1).cpu().numpy())
        all_labels.extend(labels.numpy())

cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(12,10))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix")
plt.show()

"""Модель уверенно различает:

- пастбища

- дороги

- лесные массивы

- водные поверхности

- жилые районы

Во всех показанных примерах истинная метка совпадает с предсказанной, что подтверждает хорошее качество модели на реальных образцах.
"""

# Примеры предсказаний

model.eval()
imgs, labels = next(iter(val_loader))
plt.figure(figsize=(12,6))
for i in range(8):
    idx = random.randint(0, len(imgs)-1)
    img = imgs[idx]
    true_label = class_names[labels[idx]]
    with torch.no_grad():
        pred_label = class_names[model(img.unsqueeze(0).to(DEVICE)).argmax(1).item()]
    img_disp = img.permute(1,2,0).numpy()
    img_disp = img_disp * np.array([0.229,0.224,0.225]) + np.array([0.485,0.456,0.406])
    img_disp = np.clip(img_disp, 0, 1)
    plt.subplot(2,4,i+1)
    plt.imshow(img_disp)
    plt.title(f"True: {true_label}\nPred: {pred_label}")
    plt.axis("off")
plt.show()

"""Выводы

1. Успешно выполнено трансферное обучение ResNet-50 на EuroSAT.

2. Заморозка предобученных слоёв значительно ускорила обучение.

3. Модель достигла высокой точности 94.2% на валидации.

4. Ошибки возникают в похожих по структуре ландшафтах (что естественно для спутниковых данных).

5. Трансферное обучение доказало свою эффективность: всего за 10 эпох удалось достичь высокой точности.

Возможные улучшения

1. Дообучить часть ResNet-50 (unfreeze last layers).

2. Использовать более сильные аугментации (CutMix, RandomErasing).

3. Попробовать EfficientNet-B0/B3.

4. Применить scheduler для обучения.
"""