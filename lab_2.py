# -*- coding: utf-8 -*-
"""Вторая_Лабораторная.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JpJk61JUCqMtxqs9DG83QYt6j8OAGtOn

**Предсказание оттока клиентов банка**

**Цель проекта**

Разработать и оценить модели машинного обучения для предсказания оттока клиентов банка с учётом дисбаланса классов, чтобы своевременно выявлять клиентов с высоким риском ухода и предоставлять бизнесу инструмент для повышения удержания клиентов и оптимизации маркетинговых затрат. В качестве базовой модели использовалась LogisticRegression для оценки исходного качества и последующего сравнения с моделями, учитывающими дисбаланс классов (RandomForest, LightGBM, CatBoost).

**Задачи проекта**

1. Сбор и первичная обработка данных

- Загрузить данные о клиентах банка.

- Проверить типы столбцов, наличие пропусков и дубликатов.

- Привести типы данных к корректным форматам (числовые, категориальные, булевые).

2. Очистка и подготовка признаков

- Обработать пропуски (например, заполнение медианой для Tenure).

- Удалить неинформативные признаки (RowNumber, CustomerId, Surname).

- Провести кодирование категориальных признаков (one-hot encoding).

3. Анализ дисбаланса классов

- Оценить распределение ушедших и оставшихся клиентов.

- Применить методы балансировки классов (SMOTE, class_weight) для моделей, обучаемых с учётом дисбаланса.

4. Обучение и сравнение моделей машинного обучения

- Обучить базовую модель LogisticRegression на исходных данных без балансировки.

- Обучить несколько моделей с учётом дисбаланса (RandomForest, LightGBM, CatBoost).

- Сравнить модели по F1-score и ROC AUC на тестовом наборе.

5. Оценка качества финальной модели

- Рассчитать F1-score, ROC AUC, построить матрицу ошибок и отчёт классификации.

- Построить ROC-кривые для всех моделей, чтобы визуально сравнить способность различать классы.

6. Анализ результатов и практические рекомендации

- Сравнить F1-score и ROC AUC между базовой моделью и моделями с балансировкой.

- Сделать выводы о практической значимости результатов для удержания клиентов и оптимизации маркетинговых расходов.

- Дать рекомендации по применению модели в бизнес-процессах и необходимости её периодического обновления.
"""

import numpy as np
import pandas as pd
# загрузка данных
df = pd.read_csv("/content/Bank_data (2).csv")
df

print('\nТипы столбцов:')
print(df.dtypes)

print('\nПропуски по столбцам:')
print(df.isna().sum())

print('\nКоличество дубликатов:')
print(df.duplicated().sum())

# приведение типов данных
bool_cols = df.select_dtypes(include='bool').columns
df[bool_cols] = df[bool_cols].astype(int)  # True/False -> 1/0

cat_cols = ['Geography', 'Gender']  # категориальные колонки
df[cat_cols] = df[cat_cols].astype('category')

num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']
df[num_cols] = df[num_cols].astype(float)  # числовые к float

# обработка пропущенных значений
median_tenure = df['Tenure'].median()
df['Tenure'] = df['Tenure'].fillna(median_tenure)

# удаление неинформативных колонок
df = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])

df

from sklearn.model_selection import train_test_split

# разделяее признаков и целевой переменной
y_target = df.pop('Exited')  # удаляем 'Exited' из data и сохраняем в y_target
X_features = df.copy()       # создаём копию оставшихся признаков

# создаём обучающую и тестовую выборки с сохранением пропорций классов
X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(
    X_features, y_target,
    test_size=0.2,
    random_state=42,
    stratify=y_target
)

# оценка дисперсии целевой переменной в каждой выборке
print("Дисперсия таргета в train:", np.var(y_train_split))
print("Дисперсия таргета в test :", np.var(y_test_split))

import matplotlib.pyplot as plt
import seaborn as sns
# DataFrame для удобства визуализации
dist_df = pd.DataFrame({
    'train': y_train_split,
    'test': y_test_split
})

plt.figure(figsize=(10,4))

# распределение классов в обучающей выборке
plt.subplot(1,2,1)
sns.countplot(x=dist_df['train'])
plt.title('Распределение классов в train')
plt.xlabel('Exited')
plt.ylabel('Количество')

# распределение классов в тестовой выборке
plt.subplot(1,2,2)
sns.countplot(x=dist_df['test'])
plt.title('Распределение классов в test')
plt.xlabel('Exited')
plt.ylabel('Количество')

plt.tight_layout()
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1. One-hot кодирование категориальных признаков
cat_cols = X_train_split.select_dtypes(include='category').columns
X_train_enc = pd.get_dummies(X_train_split, columns=cat_cols, drop_first=True)
X_test_enc  = pd.get_dummies(X_test_split,  columns=cat_cols, drop_first=True)

# Убедимся, что колонки совпадают
X_test_enc = X_test_enc.reindex(columns=X_train_enc.columns, fill_value=0)

# 2. Создаём модель
log_reg = LogisticRegression(random_state=42, max_iter=1000)

# 3. Обучаем модель
log_reg.fit(X_train_enc, y_train_split)

# 4. Предсказания и оценка качества
y_pred = log_reg.predict(X_test_enc)

print(f"Точность модели: {accuracy_score(y_test_split, y_pred):.4f}")
print("\nМатрица ошибок:")
print(confusion_matrix(y_test_split, y_pred))
print("\nОтчёт классификации:")
print(classification_report(y_test_split, y_pred))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# 1. Создаём базовую логистическую регрессию
model_lr = LogisticRegression(random_state=42, max_iter=10000)

# 2. Обучаем на тренировочных данных
model_lr.fit(X_train_enc, y_train_split)

# 3. Предсказания классов и вероятностей для теста
y_pred = model_lr.predict(X_test_enc)
y_prob = model_lr.predict_proba(X_test_enc)[:, 1]  # вероятность класса 1

# 4. Метрики качества
f1 = f1_score(y_test_split, y_pred)
roc_auc = roc_auc_score(y_test_split, y_prob)

print(f"F1-score на тесте: {f1:.3f}")
print(f"ROC AUC на тесте: {roc_auc:.3f}")

# 5. Построение ROC-кривой
fpr, tpr, _ = roc_curve(y_test_split, y_prob)

plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Logistic Regression (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривая')
plt.legend(loc='lower right')
plt.grid(alpha=0.3)
plt.show()

!pip install catboost

import matplotlib.pyplot as plt
from sklearn.metrics import f1_score, roc_curve, roc_auc_score
from imblearn.over_sampling import SMOTE

from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# Балансировка через SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train_enc, y_train_split)

# Модели с учётом дисбаланса
models = {
    "RandomForest": RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),
    "LightGBM": LGBMClassifier(n_estimators=500, class_weight='balanced', random_state=42, verbose=-1),
    "CatBoost": CatBoostClassifier(iterations=500, auto_class_weights='Balanced', random_state=42, verbose=0)
}

# Обучение моделей и оценка F1
f1_scores = {}
for name, model in models.items():
    model.fit(X_res, y_res)
    y_pred = model.predict(X_test_enc)
    f1 = f1_score(y_test_split, y_pred)
    f1_scores[name] = f1
    print(f"{name} — F1 : {f1:.4f}")

# Выбираем лучшую модель
best_model_name = max(f1_scores, key=f1_scores.get)
best_model = models[best_model_name]
print(f"\nЛучшая модель по F1: {best_model_name} с F1 = {f1_scores[best_model_name]:.4f}")

# Построение ROC-кривых
plt.figure(figsize=(8,6))

for name, model in models.items():
    y_proba = model.predict_proba(X_test_enc)[:, 1]
    fpr, tpr, _ = roc_curve(y_test_split, y_proba)
    auc_score = roc_auc_score(y_test_split, y_proba)
    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {auc_score:.3f})')

plt.plot([0,1], [0,1], color='black', linestyle='--', lw=1)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривые моделей с балансировкой классов')
plt.legend(loc='lower right')
plt.grid(alpha=0.3)
plt.show()

# финальное тестирование
y_pred_final = best_model.predict(X_test_enc)
y_proba_final = best_model.predict_proba(X_test_enc)[:, 1]

# метрики
f1 = f1_score(y_test_split, y_pred_final)
roc_auc = roc_auc_score(y_test_split, y_proba_final)

print(f"Финальная модель: {best_model_name}")
print(f"F1-score на независимом тесте: {f1:.4f}")
print(f"ROC AUC на независимом тесте: {roc_auc:.4f}\n")

# матрица ошибок
print("Матрица ошибок (Confusion Matrix):")
print(confusion_matrix(y_test_split, y_pred_final))

# подробный отчёт классификации
print("\nПодробный отчёт классификации:")
print(classification_report(y_test_split, y_pred_final))

# ROC-кривая финальной модели
fpr, tpr, _ = roc_curve(y_test_split, y_proba_final)
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, lw=2, label=f'{best_model_name} (AUC = {roc_auc:.3f})')
plt.plot([0,1], [0,1], color='black', linestyle='--', lw=1)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривая финальной модели на независимом тесте')
plt.legend(loc='lower right')
plt.grid(alpha=0.3)
plt.show()

"""**Этапы очистки данных**

1. Загрузка и первичный анализ данных:

- Считали CSV-файл с данными о клиентах банка.

- Проверили типы столбцов, наличие пропусков и дубликатов.

2. Обработка пропусков:

- Для числового признака Tenure пропуски были заполнены медианой, так как она устойчива к выбросам.

3. Приведение типов данных:

Булевые значения (True/False) преобразованы в 0/1.

- Категориальные признаки (Geography, Gender) приведены к типу category.

- Числовые признаки (CreditScore, Age, Balance, NumOfProducts, EstimatedSalary, Tenure) приведены к типу float для корректной работы алгоритмов машинного обучения.

4. Удаление неинформативных колонок:

- Удалены RowNumber, CustomerId, Surname, так как они не содержат полезной информации для модели предсказания ухода клиента.

5. Кодирование категориальных признаков:

- Применено one-hot кодирование для Geography и Gender.

6. Проверка распределения классов:

- Построены графики распределения классов в тренировочной и тестовой выборках.

- Выявлен дисбаланс классов: доля ушедших клиентов меньше доли оставшихся.

**Подходы к работе с дисбалансом**

1. SMOTE (Synthetic Minority Oversampling Technique):

- Синтетическое увеличение числа примеров редкого класса в тренировочной выборке.

- Обеспечивает равное количество ушедших и оставшихся клиентов для корректного обучения модели.

2. Взвешивание классов в моделях:

- Для RandomForest и LightGBM использован параметр class_weight='balanced'.

- Для CatBoost включена опция auto_class_weights='Balanced'.

- Это позволяет модели учитывать дисбаланс без изменения данных.

**Результаты обучения моделей**
| Модель       | F1-score | ROC AUC |
| ------------ | -------- | ------- |
| RandomForest | 0.611    | 0.855   |
| LightGBM     | 0.579    | 0.836   |
| CatBoost     | 0.603    | 0.860   |

- Построены ROC-кривые для всех моделей, которые показывают способность моделей различать классы при всех порогах.

- Лучшая модель по F1-score: RandomForest (F1 = 0.611).

**Графики:**

- Распределение классов в train/test

- ROC-кривые моделей

**Сравнение F1-score и ROC AUC**

- F1-score отражает баланс между точностью (precision) и полнотой (recall) для конкретного порога классификации.

- ROC AUC оценивает способность модели различать классы на всех возможных порогах.

- Если ROC AUC выше F1, это значит, что модель умеет хорошо различать классы, но выбранный порог классификации можно оптимизировать для повышения F1.

**Практическая значимость:**

- F1-score критичен для бизнеса, когда важно не пропустить клиентов, склонных к уходу, и одновременно не тратить ресурсы на удержание тех, кто останется.

- ROC AUC показывает, что модель способна различать уходящих и остающихся клиентов с высокой вероятностью.

**Краткий анализ и рекомендации**

1. Использование модели:

- RandomForest с балансировкой классов подходит для раннего выявления клиентов с высоким риском ухода.

- Можно применять модель для таргетированных маркетинговых кампаний и программ удержания клиентов.

2. Оптимизация порога классификации:

- Для повышения F1-score рекомендуется подобрать оптимальный порог вероятности (например, с помощью кривой precision-recall), чтобы балансировать между удержанием клиентов и затратами на маркетинг.

3. Регулярное обновление модели:

Поведение клиентов меняется со временем, поэтому модель нужно периодически переобучать на новых данных.

4. Практическая ценность метрик:

- F1-score = 0.611 — модель достаточно точна для принятия бизнес-решений.

- ROC AUC = 0.855 — высокая способность различать классы, что позволяет снизить риск ошибок при принятии решений.
"""